{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7d4277",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15023a01",
   "metadata": {},
   "source": [
    "# Train and Evaluate different models\n",
    "This will be the main notebook for generating our data for this project. We aim to run experiments on the models and validate our hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54ee29",
   "metadata": {},
   "source": [
    "# Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f557a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\ger85847\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ger85847\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ger85847\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ger85847\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Using cached scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e4a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Linear Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC # \"C\" stands for Classification\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Ensembles (Random Forest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "# [cite: 32-33]\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd91273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Close      High       Low      Open     Volume\n",
      "0  6.424606  6.439316  6.375673  6.407194  493729600\n",
      "1  6.435713  6.472038  6.401790  6.442318  601904800\n",
      "2  6.333346  6.461232  6.326741  6.435714  552160000\n",
      "3  6.321635  6.364264  6.275704  6.356759  477131200\n",
      "4  6.363663  6.364264  6.276005  6.313229  447610800 0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "def load_into_df(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    y = df['Target']\n",
    "    x = df.drop(columns='Target')\n",
    "    return x, y\n",
    "\n",
    "X_train_basic, Y_train_basic = load_into_df(\"../data/dataset1_train.csv\")\n",
    "print(X_train_basic.head(5), Y_train_basic.head(5))\n",
    "\n",
    "X_test_basic, Y_test_basic = load_into_df(\"../data/dataset1_test.csv\")\n",
    "\n",
    "X_train_calculated, Y_train_calculated = load_into_df(\"../data/dataset2_train.csv\")\n",
    "X_test_calculated, Y_test_calculated = load_into_df(\"../data/dataset2_test.csv\")\n",
    "datasets = [(\"basic\", X_train_basic, Y_train_basic, X_test_basic, Y_test_basic), (\"calculated\", X_train_calculated, Y_train_calculated, X_test_calculated, Y_test_calculated)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5f2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "models_to_run = {\n",
    "    \"Logistic Regression\": LogisticRegression(solver='liblinear'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"MLP\": MLPClassifier(random_state=42, max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ab851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  Logistic Regression  on  basic\n",
      "0.523936170212766 0.523936170212766 1.0 0.68760907504363\n",
      "Training  Logistic Regression  on  calculated\n",
      "0.523936170212766 0.523936170212766 1.0 0.68760907504363\n",
      "Training  Decision Tree  on  basic\n",
      "0.4940159574468085 0.5157159487776485 0.5621827411167513 0.5379477838494232\n",
      "Training  Decision Tree  on  calculated\n",
      "0.4867021276595745 0.5132013201320133 0.3946700507614213 0.44619799139167865\n",
      "Training  Random Forest  on  basic\n",
      "0.4940159574468085 0.5170239596469105 0.5203045685279187 0.5186590765338394\n",
      "Training  Random Forest  on  calculated\n",
      "0.5106382978723404 0.5294117647058824 0.5939086294416244 0.5598086124401914\n",
      "Training  SVM  on  basic\n",
      "0.523936170212766 0.523936170212766 1.0 0.68760907504363\n",
      "Training  SVM  on  calculated\n",
      "0.523936170212766 0.523936170212766 1.0 0.68760907504363\n",
      "Training  MLP  on  basic\n",
      "0.523936170212766 0.523936170212766 1.0 0.68760907504363\n",
      "Training  MLP  on  calculated\n",
      "0.523936170212766 0.523936170212766 1.0 0.68760907504363\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models_to_run.items():\n",
    "    for name, X_train, Y_train, X_test, Y_test in datasets:\n",
    "        print(\"Training \", model_name, \" on \", name)\n",
    "        model.fit(X_train, Y_train)\n",
    "        # 2. Get predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # 3. Evaluate (using your proposal's metrics [cite: 29])\n",
    "        accuracy = accuracy_score(Y_test, y_pred)\n",
    "        precision = precision_score(Y_test, y_pred)\n",
    "        recall = recall_score(Y_test,y_pred)\n",
    "        F1 = f1_score(Y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {F1}\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
