{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Direction Prediction - Dataset Generation\n",
    "\n",
    "This notebook generates two datasets for predicting stock price direction:\n",
    "1. **Basic Dataset**: Raw OHLCV data with binary target\n",
    "2. **Enhanced Dataset**: OHLCV data + technical indicators with binary target\n",
    "\n",
    "## Setup and Data Collection\n",
    "- Tickers: Top 50 S&P 500 stocks by market cap\n",
    "- Date Range: 2010-01-01 to 2024-12-31\n",
    "- Train/Test Split: 2010-2021 (Train), 2022-2024 (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas methods used in this notebook — quick reference\n",
    "\n",
    "Below are concise, actionable descriptions of the DataFrame/Series methods and operations that appear in this notebook. Each item shows what it does and a brief example of the effect.\n",
    "\n",
    "- shift(n)\n",
    "  - Moves values up/down along the index. Commonly used to compare current row with next/previous row.\n",
    "  - Example: df['Close'].shift(-1) gives next-day close.\n",
    "\n",
    "- astype(type)\n",
    "  - Casts dtype of a Series (or DataFrame) to the given type.\n",
    "  - Example: (next_close > df['Close']).astype(int) converts boolean to 0/1.\n",
    "\n",
    "- df.columns (assignment)\n",
    "  - Replace column labels. Used here to flatten MultiIndex columns by joining parts or taking the last part.\n",
    "  - Example: df.columns = [f\"{p}_{t}\" for p,t in df.columns]\n",
    "\n",
    "- isinstance(df.columns, pd.MultiIndex)\n",
    "  - Checks whether columns have multiple levels (e.g., (Price, Ticker)). If true, you may want to flatten or stack.\n",
    "\n",
    "- get_level_values(level)\n",
    "  - Returns the labels for a specific MultiIndex level (useful to find empty tickers or particular level values).\n",
    "  - Example: df.columns.get_level_values('Ticker')\n",
    "\n",
    "- stack(level)\n",
    "  - Moves one column-level into the row index, turning wide MultiIndex columns into long rows. Use when you want a tidy table with a Ticker column.\n",
    "  - Example: df.stack(level='Ticker') → index becomes (original_index, Ticker) and price labels stay as columns.\n",
    "\n",
    "- reset_index()\n",
    "  - Converts index levels into columns and resets index to default integer index.\n",
    "  - Often used after stack() to get a flat DataFrame: df.stack(...).reset_index()\n",
    "\n",
    "- sort_values(by)\n",
    "  - Sorts rows by one or more columns. Important before groupby operations that assume ordering.\n",
    "  - Example: df.sort_values(['Ticker','Date'])\n",
    "\n",
    "- reset_index(drop=True)\n",
    "  - Reset index and drop the old index instead of adding it as a column.\n",
    "\n",
    "- groupby(...).apply(func)\n",
    "  - Group rows and apply a function to each group. Useful for per-ticker operations, e.g., remove last row for each ticker: df.groupby('Ticker').apply(lambda x: x.iloc[:-1])\n",
    "\n",
    "- iloc / loc\n",
    "  - iloc: integer-location based selection. loc: label-based selection. Both used to select rows/columns precisely.\n",
    "  - Example: x.iloc[:-1] takes all but the last row of group x. dataset2.loc[mask, 'SMA_10'] assigns values to rows matching mask.\n",
    "\n",
    "- unique()\n",
    "  - Returns unique values in a Series (e.g., list of tickers).\n",
    "\n",
    "- isnull().sum()\n",
    "  - Counts missing values per column.\n",
    "\n",
    "- dropna()\n",
    "  - Drops rows (or columns) containing NA. Here used to remove rows missing indicator values after rolling/ewm computations.\n",
    "\n",
    "- rolling(window).mean()\n",
    "  - Computes rolling statistics (SMA) over a window of rows.\n",
    "  - Example: df['Close'].rolling(10).mean() gives 10-day SMA.\n",
    "\n",
    "- diff()\n",
    "  - First discrete difference on Series: current - previous. Used to compute gains/losses for RSI.\n",
    "\n",
    "- where(condition, other)\n",
    "  - Keeps values where condition True, else replaces with other. Useful to separate gains (positive diffs) from losses.\n",
    "\n",
    "- ewm(span, adjust=False).mean()\n",
    "  - Exponential weighted mean (EMA). Used for MACD and signal smoothing.\n",
    "\n",
    "- drop_duplicates()\n",
    "  - Remove duplicate rows (not used heavily here but commonly used when combining datasets).\n",
    "\n",
    "- to_csv / to_parquet\n",
    "  - Persist DataFrame to disk in CSV or Parquet formats.\n",
    "\n",
    "- melt(id_vars, var_name, value_name)\n",
    "  - Unpivot a DataFrame from wide to long format. Use when you flattened column names like 'Close_AAPL' and want rows per ticker.\n",
    "  - Example: df.reset_index().melt(id_vars='Date')\n",
    "\n",
    "- str.rsplit(sep, n=1, expand=True)\n",
    "  - Split string column from right into parts. Useful to split 'Close_AAPL' into ['Close','AAPL'].\n",
    "\n",
    "- copy()\n",
    "  - Create an explicit copy of a DataFrame to avoid modifying the original view in-place.\n",
    "\n",
    "- head(n) / shape / columns / value_counts() / mean()\n",
    "  - Utility methods: head shows top rows, shape gives (rows, cols), columns lists column names, value_counts gives counts per value, mean gives average (useful for target balance).\n",
    "\n",
    "Tip: for tidy machine learning datasets prefer the long form (one row per Date+Ticker) produced by stacking or melting — columns: Date, Ticker, Open, High, Low, Close, Volume, indicators..., Target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get Top 50 S&P 500 Stocks by Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 tickers for the dataset:\n",
      "['AAPL', 'MSFT']\n"
     ]
    }
   ],
   "source": [
    "# Get S&P 500 tickers from Wikipedia (robust)\n",
    "top_50_tickers = ['AAPL', 'MSFT']\n",
    "                  #, 'AMZN', 'GOOGL', 'BRK-B', 'JPM', 'JNJ', 'PG', 'V', 'UNH']\n",
    "# yfinance expects '-' instead of '.' for tickers like BRK.B\n",
    "top_50_tickers = [t.replace('.', '-').strip() for t in top_50_tickers]\n",
    "\n",
    "print(f\"Using {len(top_50_tickers)} tickers for the dataset:\")\n",
    "print(top_50_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "# Replace Wikipedia scraping with a fixed list of 10 tickers public since 2010\n",
    "\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading historical data from 2010-01-01 to 2024-12-31...\n",
      "\n",
      "Downloading AAPL... OK (3773 rows)\n",
      "Index(['Close', 'High', 'Low', 'Open', 'Volume', 'Target'], dtype='object', name='Price')\n",
      "OK (3773 rows)\n",
      "Index(['Close', 'High', 'Low', 'Open', 'Volume', 'Target'], dtype='object', name='Price')\n",
      "Downloading MSFT... Downloading MSFT... OK (3773 rows)\n",
      "Index(['Close', 'High', 'Low', 'Open', 'Volume', 'Target'], dtype='object', name='Price')\n",
      "OK (3773 rows)\n",
      "Index(['Close', 'High', 'Low', 'Open', 'Volume', 'Target'], dtype='object', name='Price')\n"
     ]
    }
   ],
   "source": [
    "# Define date ranges\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "print(f\"Downloading historical data from {start_date} to {end_date}...\\n\")\n",
    "\n",
    "# Download data for all tickers\n",
    "all_data = []\n",
    "\n",
    "if not top_50_tickers:\n",
    "    raise RuntimeError(\"No tickers available to download. Check the Wikipedia scraping step.\")\n",
    "\n",
    "for ticker in top_50_tickers:\n",
    "    try:\n",
    "        print(f\"Downloading {ticker}...\", end=' ')\n",
    "        \n",
    "        df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        \n",
    "        if not df.empty:\n",
    "            next_close = df['Close'].shift(-1)\n",
    "            df['Target'] = (next_close > df['Close']).astype(int)\n",
    "            \n",
    "            \n",
    "            all_data.append(df)\n",
    "            print(f\"OK ({len(df)} rows)\")\n",
    "            \n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = df.columns.droplevel('Ticker')\n",
    "                print(df.columns)\n",
    "        else:\n",
    "            print(\"No data available\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    time.sleep(0.5)  # be polite to the data provider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data ---------------------------------------------\n",
      "Price            Close        High         Low        Open     Volume  Target\n",
      "Date                                                                         \n",
      "2010-01-04    6.424606    6.439316    6.375673    6.407194  493729600       1\n",
      "2010-01-05    6.435713    6.472038    6.401790    6.442318  601904800       0\n",
      "2010-01-06    6.333346    6.461232    6.326741    6.435714  552160000       0\n",
      "2010-01-07    6.321635    6.364264    6.275704    6.356759  477131200       1\n",
      "2010-01-08    6.363663    6.364264    6.276005    6.313229  447610800       0\n",
      "...                ...         ...         ...         ...        ...     ...\n",
      "2024-12-23  254.367035  254.745680  252.553466  253.868804   40858800       1\n",
      "2024-12-24  257.286682  257.296626  254.386957  254.586262   23234700       1\n",
      "2024-12-26  258.103729  259.179926  256.718662  257.276679   27237100       0\n",
      "2024-12-27  254.685883  257.784897  252.164833  256.917949   42355300       0\n",
      "2024-12-30  251.307861  252.603266  249.862994  251.337754   35557500       0\n",
      "\n",
      "[3773 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine all data\n",
    "if not all_data:\n",
    "    raise RuntimeError(\"No data was downloaded for any tickers. Aborting.\")\n",
    "\n",
    "\n",
    "raw_data = all_data\n",
    "print('raw_data ---------------------------------------------')\n",
    "print(raw_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Dataset 1 - Basic OHLCV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 (Basic) created\n",
      "Price          Close      High       Low      Open     Volume  Target\n",
      "Date                                                                 \n",
      "2010-01-04  6.424606  6.439316  6.375673  6.407194  493729600       1\n",
      "2010-01-05  6.435713  6.472038  6.401790  6.442318  601904800       0\n",
      "2010-01-06  6.333346  6.461232  6.326741  6.435714  552160000       0\n",
      "2010-01-07  6.321635  6.364264  6.275704  6.356759  477131200       1\n",
      "2010-01-08  6.363663  6.364264  6.276005  6.313229  447610800       0\n",
      "2010-01-11  6.307528  6.394286  6.257694  6.388282  462229600       0\n",
      "2010-01-12  6.235775  6.297317  6.196749  6.279904  594459600       1\n",
      "2010-01-13  6.323738  6.332143  6.127107  6.240283  605892000       0\n",
      "2010-01-14  6.287114  6.318035  6.274806  6.307528  432894000       0\n",
      "2010-01-15  6.182041  6.352255  6.180239  6.332141  594067600       1\n"
     ]
    }
   ],
   "source": [
    "# Dataset 1: Basic OHLCV + Target\n",
    "dataset1 = [data.copy(deep=True) for data in raw_data]\n",
    "print(f\"Dataset 1 (Basic) created\")\n",
    "print(dataset1[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Calculate Technical Indicators for Dataset 2\n",
    "\n",
    "Technical indicators to calculate:\n",
    "- **Simple Moving Averages (SMA)**: 10-day, 50-day, 200-day\n",
    "- **Relative Strength Index (RSI)**: 14-day period\n",
    "- **MACD**: 12, 26, 9 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical indicator functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_sma(data, window):\n",
    "    \"\"\"Calculate Simple Moving Average\"\"\"\n",
    "    return data.rolling(window=window).mean()\n",
    "\n",
    "def calculate_rsi(data, window=14):\n",
    "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_macd(data, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calculate MACD and Signal line\"\"\"\n",
    "    ema_fast = data.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = data.ewm(span=slow, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
    "    return macd, signal_line\n",
    "\n",
    "print(\"Technical indicator functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating technical indicators for each ticker...\n",
      "\n",
      "Price          Close      High       Low      Open      Volume  Target  \\\n",
      "Date                                                                     \n",
      "2010-10-18  9.546397  9.576416  9.435022  9.560507  1093010800       0   \n",
      "2010-10-19  9.290925  9.419411  9.006635  9.108103  1232784000       1   \n",
      "2010-10-20  9.322147  9.433822  9.212274  9.276217   721624400       0   \n",
      "2010-10-21  9.291825  9.448530  9.210170  9.377082   551460000       0   \n",
      "2010-10-22  9.230284  9.307435  9.195161  9.278315   372778000       1   \n",
      "\n",
      "Price         SMA-10    SMA-50   SMA-200        RSI      MACD  Signal_Line  \n",
      "Date                                                                        \n",
      "2010-10-18  8.977545  8.119300  7.369385  82.037051  0.321408     0.264017  \n",
      "2010-10-19  9.039236  8.147964  7.383716  69.540556  0.321679     0.275549  \n",
      "2010-10-20  9.103299  8.178656  7.398148  74.787160  0.320716     0.284582  \n",
      "2010-10-21  9.164240  8.214278  7.412941  75.092971  0.313888     0.290444  \n",
      "2010-10-22  9.204467  8.247708  7.427484  77.736986  0.300052     0.292365  \n",
      "Price           Close       High        Low       Open    Volume  Target  \\\n",
      "Date                                                                       \n",
      "2010-10-18  19.614450  19.713207  19.333377  19.439729  48330500       0   \n",
      "2010-10-19  19.067503  19.272612  18.953554  19.196645  66150900       1   \n",
      "2010-10-20  19.227032  19.295401  19.067503  19.189049  56283600       1   \n",
      "2010-10-21  19.310595  19.401755  19.029519  19.295401  50032400       0   \n",
      "2010-10-22  19.280203  19.401750  19.196641  19.386556  25837900       0   \n",
      "\n",
      "Price          SMA-10     SMA-50    SMA-200        RSI      MACD  Signal_Line  \n",
      "Date                                                                           \n",
      "2010-10-18  18.933039  18.651657  20.480073  69.654683  0.162362     0.057888  \n",
      "2010-10-19  18.990014  18.645973  20.459543  58.721058  0.154604     0.077232  \n",
      "2010-10-20  19.056865  18.651640  20.439774  61.263739  0.159490     0.093683  \n",
      "2010-10-21  19.124475  18.662153  20.421135  64.285897  0.168167     0.108580  \n",
      "2010-10-22  19.186007  18.677649  20.403541  72.897140  0.170624     0.120989  \n"
     ]
    }
   ],
   "source": [
    "# Create Dataset 2 with technical indicators\n",
    "dataset2 = [data.copy(deep=True) for data in raw_data]\n",
    "\n",
    "print(\"Calculating technical indicators for each ticker...\\n\")\n",
    "\n",
    "for i in range(len(dataset2)):\n",
    "    ticker_data = dataset2[i]\n",
    "    ticker_data['SMA-10'] = calculate_sma(ticker_data['Close'], 10)\n",
    "    ticker_data['SMA-50'] = calculate_sma(ticker_data['Close'], 50)\n",
    "    ticker_data['SMA-200'] = calculate_sma(ticker_data['Close'], 200)\n",
    "    \n",
    "    ticker_data['RSI'] = calculate_rsi(ticker_data['Close'])\n",
    "    \n",
    "    ticker_data['MACD'], ticker_data['Signal_Line'] = calculate_macd(ticker_data['Close'])\n",
    "\n",
    "    dataset2[i] = ticker_data.dropna()\n",
    "    \n",
    "    print(dataset2[i].head(5))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Clean Data - Drop Rows with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Split Data into Train and Test Sets\n",
    "\n",
    "- **Training**: 2010-2021\n",
    "- **Testing**: 2022-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price          Close      High       Low      Open     Volume  Target\n",
      "Date                                                                 \n",
      "2010-01-04  6.424606  6.439316  6.375673  6.407194  493729600       1\n",
      "2010-01-05  6.435713  6.472038  6.401790  6.442318  601904800       0\n",
      "2010-01-06  6.333346  6.461232  6.326741  6.435714  552160000       0\n",
      "2010-01-07  6.321635  6.364264  6.275704  6.356759  477131200       1\n",
      "2010-01-08  6.363663  6.364264  6.276005  6.313229  447610800       0\n",
      "Price          Close      High       Low      Open      Volume  Target  \\\n",
      "Date                                                                     \n",
      "2010-10-18  9.546397  9.576416  9.435022  9.560507  1093010800       0   \n",
      "2010-10-19  9.290925  9.419411  9.006635  9.108103  1232784000       1   \n",
      "2010-10-20  9.322147  9.433822  9.212274  9.276217   721624400       0   \n",
      "2010-10-21  9.291825  9.448530  9.210170  9.377082   551460000       0   \n",
      "2010-10-22  9.230284  9.307435  9.195161  9.278315   372778000       1   \n",
      "\n",
      "Price         SMA-10    SMA-50   SMA-200        RSI      MACD  Signal_Line  \n",
      "Date                                                                        \n",
      "2010-10-18  8.977545  8.119300  7.369385  82.037051  0.321408     0.264017  \n",
      "2010-10-19  9.039236  8.147964  7.383716  69.540556  0.321679     0.275549  \n",
      "2010-10-20  9.103299  8.178656  7.398148  74.787160  0.320716     0.284582  \n",
      "2010-10-21  9.164240  8.214278  7.412941  75.092971  0.313888     0.290444  \n",
      "2010-10-22  9.204467  8.247708  7.427484  77.736986  0.300052     0.292365  \n",
      "============================================================\n",
      "Dataset 1 (Basic OHLCV)\n",
      "============================================================\n",
      "Training set: 6,042 rows (2010-01-04 00:00:00 to 2021-12-31 00:00:00)\n",
      "Testing set:  1,504 rows (2022-01-03 00:00:00 to 2024-12-30 00:00:00)\n",
      "\n",
      "Target distribution - Train: 52.81% positive\n",
      "Target distribution - Test:  52.39% positive\n",
      "\n",
      "============================================================\n",
      "Dataset 2 (With Technical Indicators)\n",
      "============================================================\n",
      "Training set: 5,644 rows (2010-10-18 00:00:00 to 2021-12-31 00:00:00)\n",
      "Testing set:  1,504 rows (2022-01-03 00:00:00 to 2024-12-30 00:00:00)\n",
      "\n",
      "Target distribution - Train: 52.69% positive\n",
      "Target distribution - Test:  52.39% positive\n"
     ]
    }
   ],
   "source": [
    "# Define split date\n",
    "split_date = '2022-01-01'\n",
    "\n",
    "# Combine the DFs\n",
    "\n",
    "dataset1_full = pd.concat(dataset1)\n",
    "\n",
    "\n",
    "dataset2_full = pd.concat(dataset2)\n",
    "\n",
    "print(dataset1_full.head(5))\n",
    "print(dataset2_full.head(5))\n",
    "\n",
    "# Split Dataset 1\n",
    "\n",
    "dataset1_train = dataset1_full[dataset1_full.index < split_date].copy()\n",
    "dataset1_test = dataset1_full[dataset1_full.index >= split_date].copy()\n",
    "\n",
    "# Split Dataset 2\n",
    "dataset2_train = dataset2_full[dataset2_full.index < split_date].copy()\n",
    "dataset2_test = dataset2_full[dataset2_full.index >= split_date].copy()\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Dataset 1 (Basic OHLCV)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training set: {dataset1_train.shape[0]:,} rows ({dataset1_train.index.min()} to {dataset1_train.index.max()})\")\n",
    "print(f\"Testing set:  {dataset1_test.shape[0]:,} rows ({dataset1_test.index.min()} to {dataset1_test.index.max()})\")\n",
    "print(f\"\\nTarget distribution - Train: {dataset1_train['Target'].mean()*100:.2f}% positive\")\n",
    "print(f\"Target distribution - Test:  {dataset1_test['Target'].mean()*100:.2f}% positive\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Dataset 2 (With Technical Indicators)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training set: {dataset2_train.shape[0]:,} rows ({dataset2_train.index.min()} to {dataset2_train.index.max()})\")\n",
    "print(f\"Testing set:  {dataset2_test.shape[0]:,} rows ({dataset2_test.index.min()} to {dataset2_test.index.max()})\")\n",
    "print(f\"\\nTarget distribution - Train: {dataset2_train['Target'].mean()*100:.2f}% positive\")\n",
    "print(f\"Target distribution - Test:  {dataset2_test['Target'].mean()*100:.2f}% positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Datasets to CSV and Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Dataset 1 (Basic OHLCV)...\n",
      "âœ“ Dataset 1 saved\n",
      "\n",
      "Saving Dataset 2 (With Technical Indicators)...\n",
      "âœ“ Dataset 1 saved\n",
      "\n",
      "Saving Dataset 2 (With Technical Indicators)...\n",
      "âœ“ Dataset 2 saved\n",
      "\n",
      "============================================================\n",
      "All datasets saved successfully!\n",
      "============================================================\n",
      "\n",
      "Files created in ../data/ directory:\n",
      "  - dataset1_train.csv / .parquet\n",
      "  - dataset1_test.csv / .parquet\n",
      "  - dataset2_train.csv / .parquet\n",
      "  - dataset2_test.csv / .parquet\n",
      "âœ“ Dataset 2 saved\n",
      "\n",
      "============================================================\n",
      "All datasets saved successfully!\n",
      "============================================================\n",
      "\n",
      "Files created in ../data/ directory:\n",
      "  - dataset1_train.csv / .parquet\n",
      "  - dataset1_test.csv / .parquet\n",
      "  - dataset2_train.csv / .parquet\n",
      "  - dataset2_test.csv / .parquet\n"
     ]
    }
   ],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "# Save Dataset 1 (Basic)\n",
    "print(\"Saving Dataset 1 (Basic OHLCV)...\")\n",
    "dataset1_train.to_csv('../data/dataset1_train.csv', index=False)\n",
    "dataset1_test.to_csv('../data/dataset1_test.csv', index=False)\n",
    "dataset1_train.to_parquet('../data/dataset1_train.parquet', index=False)\n",
    "dataset1_test.to_parquet('../data/dataset1_test.parquet', index=False)\n",
    "print(\"âœ“ Dataset 1 saved\")\n",
    "\n",
    "# Save Dataset 2 (Enhanced)\n",
    "print(\"\\nSaving Dataset 2 (With Technical Indicators)...\")\n",
    "dataset2_train.to_csv('../data/dataset2_train.csv', index=False)\n",
    "dataset2_test.to_csv('../data/dataset2_test.csv', index=False)\n",
    "dataset2_train.to_parquet('../data/dataset2_train.parquet', index=False)\n",
    "dataset2_test.to_parquet('../data/dataset2_test.parquet', index=False)\n",
    "print(\"âœ“ Dataset 2 saved\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All datasets saved successfully!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nFiles created in ../data/ directory:\")\n",
    "print(\"  - dataset1_train.csv / .parquet\")\n",
    "print(\"  - dataset1_test.csv / .parquet\")\n",
    "print(\"  - dataset2_train.csv / .parquet\")\n",
    "print(\"  - dataset2_test.csv / .parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET GENERATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "1. DATA COLLECTION\n",
      "   - Number of stocks: 2\n",
      "   - Date range: 2010-01-01 to 2024-12-31\n",
      "   - Tickers: AAPL, MSFT...\n",
      "\n",
      "2. DATASET 1 (Basic OHLCV)\n",
      "   Columns: ['Close', 'High', 'Low', 'Open', 'Volume', 'Target']\n",
      "   - Training: 6,042 rows, 6 features\n",
      "   - Testing:  1,504 rows, 6 features\n",
      "\n",
      "3. DATASET 2 (With Technical Indicators)\n",
      "   Columns: ['Close', 'High', 'Low', 'Open', 'Volume', 'Target', 'SMA-10', 'SMA-50', 'SMA-200', 'RSI', 'MACD', 'Signal_Line']\n",
      "   - Training: 5,644 rows, 12 features\n",
      "   - Testing:  1,504 rows, 12 features\n",
      "\n",
      "4. TECHNICAL INDICATORS INCLUDED\n",
      "   - SMA_10, SMA_50, SMA_200 (Simple Moving Averages)\n",
      "   - RSI_14 (Relative Strength Index)\n",
      "   - MACD, MACD_Signal, MACD_Histogram\n",
      "\n",
      "5. FILE OUTPUTS\n",
      "   CSV and Parquet formats saved to ../data/ directory\n",
      "\n",
      "================================================================================\n",
      "Dataset generation complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATASET GENERATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DATA COLLECTION\")\n",
    "print(f\"   - Number of stocks: {len(top_50_tickers)}\")\n",
    "print(f\"   - Date range: 2010-01-01 to 2024-12-31\")\n",
    "print(f\"   - Tickers: {', '.join(top_50_tickers[:10])}...\")\n",
    "\n",
    "print(\"\\n2. DATASET 1 (Basic OHLCV)\")\n",
    "print(f\"   Columns: {list(dataset1_train.columns)}\")\n",
    "print(f\"   - Training: {dataset1_train.shape[0]:,} rows, {dataset1_train.shape[1]} features\")\n",
    "print(f\"   - Testing:  {dataset1_test.shape[0]:,} rows, {dataset1_test.shape[1]} features\")\n",
    "\n",
    "print(\"\\n3. DATASET 2 (With Technical Indicators)\")\n",
    "print(f\"   Columns: {list(dataset2_train.columns)}\")\n",
    "print(f\"   - Training: {dataset2_train.shape[0]:,} rows, {dataset2_train.shape[1]} features\")\n",
    "print(f\"   - Testing:  {dataset2_test.shape[0]:,} rows, {dataset2_test.shape[1]} features\")\n",
    "\n",
    "print(\"\\n4. TECHNICAL INDICATORS INCLUDED\")\n",
    "print(\"   - SMA_10, SMA_50, SMA_200 (Simple Moving Averages)\")\n",
    "print(\"   - RSI_14 (Relative Strength Index)\")\n",
    "print(\"   - MACD, MACD_Signal, MACD_Histogram\")\n",
    "\n",
    "print(\"\\n5. FILE OUTPUTS\")\n",
    "print(\"   CSV and Parquet formats saved to ../data/ directory\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Dataset generation complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
