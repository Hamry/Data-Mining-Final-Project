{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Direction Prediction - Stationary Dataset Generation\n",
    "\n",
    "This notebook generates two datasets for predicting stock price direction:\n",
    "1. **Basic Dataset**: OHLCV data with log return and interday volitility measures with binary target (candlestick)\n",
    "\n",
    "\n",
    "2. **Enhanced Dataset**: OHLCV data + technical indicators with binary target\n",
    "\n",
    "## Setup and Data Collection\n",
    "- Tickers: Top 50 S&P 500 stocks by market cap\n",
    "- Date Range: 2010-01-01 to 2024-12-31\n",
    "- Train/Test Split: 2010-2021 (Train), 2022-2024 (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas methods used in this notebook — quick reference\n",
    "\n",
    "Below are concise, actionable descriptions of the DataFrame/Series methods and operations that appear in this notebook. Each item shows what it does and a brief example of the effect.\n",
    "\n",
    "- shift(n)\n",
    "  - Moves values up/down along the index. Commonly used to compare current row with next/previous row.\n",
    "  - Example: df['Close'].shift(-1) gives next-day close.\n",
    "\n",
    "- astype(type)\n",
    "  - Casts dtype of a Series (or DataFrame) to the given type.\n",
    "  - Example: (next_close > df['Close']).astype(int) converts boolean to 0/1.\n",
    "\n",
    "- df.columns (assignment)\n",
    "  - Replace column labels. Used here to flatten MultiIndex columns by joining parts or taking the last part.\n",
    "  - Example: df.columns = [f\"{p}_{t}\" for p,t in df.columns]\n",
    "\n",
    "- isinstance(df.columns, pd.MultiIndex)\n",
    "  - Checks whether columns have multiple levels (e.g., (Price, Ticker)). If true, you may want to flatten or stack.\n",
    "\n",
    "- get_level_values(level)\n",
    "  - Returns the labels for a specific MultiIndex level (useful to find empty tickers or particular level values).\n",
    "  - Example: df.columns.get_level_values('Ticker')\n",
    "\n",
    "- stack(level)\n",
    "  - Moves one column-level into the row index, turning wide MultiIndex columns into long rows. Use when you want a tidy table with a Ticker column.\n",
    "  - Example: df.stack(level='Ticker') → index becomes (original_index, Ticker) and price labels stay as columns.\n",
    "\n",
    "- reset_index()\n",
    "  - Converts index levels into columns and resets index to default integer index.\n",
    "  - Often used after stack() to get a flat DataFrame: df.stack(...).reset_index()\n",
    "\n",
    "- sort_values(by)\n",
    "  - Sorts rows by one or more columns. Important before groupby operations that assume ordering.\n",
    "  - Example: df.sort_values(['Ticker','Date'])\n",
    "\n",
    "- reset_index(drop=True)\n",
    "  - Reset index and drop the old index instead of adding it as a column.\n",
    "\n",
    "- groupby(...).apply(func)\n",
    "  - Group rows and apply a function to each group. Useful for per-ticker operations, e.g., remove last row for each ticker: df.groupby('Ticker').apply(lambda x: x.iloc[:-1])\n",
    "\n",
    "- iloc / loc\n",
    "  - iloc: integer-location based selection. loc: label-based selection. Both used to select rows/columns precisely.\n",
    "  - Example: x.iloc[:-1] takes all but the last row of group x. dataset2.loc[mask, 'SMA_10'] assigns values to rows matching mask.\n",
    "\n",
    "- unique()\n",
    "  - Returns unique values in a Series (e.g., list of tickers).\n",
    "\n",
    "- isnull().sum()\n",
    "  - Counts missing values per column.\n",
    "\n",
    "- dropna()\n",
    "  - Drops rows (or columns) containing NA. Here used to remove rows missing indicator values after rolling/ewm computations.\n",
    "\n",
    "- rolling(window).mean()\n",
    "  - Computes rolling statistics (SMA) over a window of rows.\n",
    "  - Example: df['Close'].rolling(10).mean() gives 10-day SMA.\n",
    "\n",
    "- diff()\n",
    "  - First discrete difference on Series: current - previous. Used to compute gains/losses for RSI.\n",
    "\n",
    "- where(condition, other)\n",
    "  - Keeps values where condition True, else replaces with other. Useful to separate gains (positive diffs) from losses.\n",
    "\n",
    "- ewm(span, adjust=False).mean()\n",
    "  - Exponential weighted mean (EMA). Used for MACD and signal smoothing.\n",
    "\n",
    "- drop_duplicates()\n",
    "  - Remove duplicate rows (not used heavily here but commonly used when combining datasets).\n",
    "\n",
    "- to_csv / to_parquet\n",
    "  - Persist DataFrame to disk in CSV or Parquet formats.\n",
    "\n",
    "- melt(id_vars, var_name, value_name)\n",
    "  - Unpivot a DataFrame from wide to long format. Use when you flattened column names like 'Close_AAPL' and want rows per ticker.\n",
    "  - Example: df.reset_index().melt(id_vars='Date')\n",
    "\n",
    "- str.rsplit(sep, n=1, expand=True)\n",
    "  - Split string column from right into parts. Useful to split 'Close_AAPL' into ['Close','AAPL'].\n",
    "\n",
    "- copy()\n",
    "  - Create an explicit copy of a DataFrame to avoid modifying the original view in-place.\n",
    "\n",
    "- head(n) / shape / columns / value_counts() / mean()\n",
    "  - Utility methods: head shows top rows, shape gives (rows, cols), columns lists column names, value_counts gives counts per value, mean gives average (useful for target balance).\n",
    "\n",
    "Tip: for tidy machine learning datasets prefer the long form (one row per Date+Ticker) produced by stacking or melting — columns: Date, Ticker, Open, High, Low, Close, Volume, indicators..., Target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get Top 50 S&P 500 Stocks by Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 tickers for the dataset:\n",
      "['AAPL', 'MSFT']\n"
     ]
    }
   ],
   "source": [
    "# Get S&P 500 tickers from Wikipedia (robust)\n",
    "top_50_tickers = ['AAPL', 'MSFT']\n",
    "                  #, 'AMZN', 'GOOGL', 'BRK-B', 'JPM', 'JNJ', 'PG', 'V', 'UNH']\n",
    "# yfinance expects '-' instead of '.' for tickers like BRK.B\n",
    "top_50_tickers = [t.replace('.', '-').strip() for t in top_50_tickers]\n",
    "\n",
    "print(f\"Using {len(top_50_tickers)} tickers for the dataset:\")\n",
    "print(top_50_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading historical data from 2010-01-01 to 2024-12-31...\n",
      "\n",
      "Downloading AAPL... OK (3773 rows)\n",
      "Downloading MSFT... OK (3773 rows)\n"
     ]
    }
   ],
   "source": [
    "# Define date ranges\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "print(f\"Downloading historical data from {start_date} to {end_date}...\\n\")\n",
    "\n",
    "# Download data for all tickers\n",
    "all_data = []\n",
    "\n",
    "\n",
    "if not top_50_tickers:\n",
    "    raise RuntimeError(\"No tickers available to download. Check the Wikipedia scraping step.\")\n",
    "\n",
    "for ticker in top_50_tickers:\n",
    "    try:\n",
    "        print(f\"Downloading {ticker}...\", end=' ')\n",
    "        \n",
    "        df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        \n",
    "        if not df.empty:\n",
    "            # 1. FIX: Flatten the columns FIRST (before appending)\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = df.columns.droplevel('Ticker')\n",
    "            \n",
    "            # 2. Add Ticker column (Crucial so you can distinguish AAPL vs MSFT later)\n",
    "            df['Ticker'] = ticker\n",
    "            \n",
    "            # 3. NOW calculate your features (using clean column names like 'Close')\n",
    "            next_close = df['Close'].shift(-1)\n",
    "            df['Target'] = (next_close > df['Close']).astype(int)\n",
    "            next_close = df['Close'].shift(-1)\n",
    "            df['Target'] = (next_close > df['Close']).astype(int)\n",
    "            # 1. Close: The main trend (Log Return from Yesterday Close to Today Close)\n",
    "            df['Log_Ret_Close'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "            \n",
    "            # 2. Open: The Overnight Move (Log Return from Yesterday Close to Today Open)\n",
    "            df['Log_Ret_Overnight'] = np.log(df['Open'] / df['Close'].shift(1))\n",
    "            \n",
    "            # 3. High/Low: The Intraday Volatility (Normalized to Open)\n",
    "            # \"How much did it swing relative to where it started?\"\n",
    "            df['High_Rel'] = df['High'] / df['Open']\n",
    "            df['Low_Rel'] = df['Low'] / df['Open']\n",
    "            \n",
    "            # 4. Volume: Log Change (Stationary growth)\n",
    "            df['Log_Vol_Change'] = np.log(df['Volume'] / df['Volume'].shift(1))\n",
    "            \n",
    "            all_data.append(df.dropna())\n",
    "            print(f\"OK ({len(df)} rows)\")\n",
    "            \n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = df.columns.droplevel('Ticker')\n",
    "                print(df.columns)\n",
    "            \n",
    "        else:\n",
    "            print(\"No data available\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    time.sleep(0.5)  # be polite to the data provider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data ---------------------------------------------\n",
      "Price            Close        High         Low        Open    Volume Ticker  \\\n",
      "Date                                                                          \n",
      "2010-01-05   23.180838   23.285662   22.941243   23.098478  49749600   MSFT   \n",
      "2010-01-06   23.038572   23.270680   22.851389   23.120932  58182400   MSFT   \n",
      "2010-01-07   22.798985   22.986168   22.604313   22.933756  50559700   MSFT   \n",
      "2010-01-08   22.956211   23.120932   22.641742   22.671692  51197400   MSFT   \n",
      "2010-01-11   22.664215   23.031095   22.551905   22.993658  68754700   MSFT   \n",
      "...                ...         ...         ...         ...       ...    ...   \n",
      "2024-12-23  432.871429  435.258308  430.464641  434.353277  19152500   MSFT   \n",
      "2024-12-24  436.929108  437.197652  431.817213  432.274691   7164500   MSFT   \n",
      "2024-12-26  435.715790  438.530341  434.243897  436.680490   8194200   MSFT   \n",
      "2024-12-27  428.177216  432.841588  424.020066  432.224981  18117700   MSFT   \n",
      "2024-12-30  422.508331  425.213468  419.594351  423.731620  13158700   MSFT   \n",
      "\n",
      "Price       Target  Log_Ret_Close  Log_Ret_Overnight  High_Rel   Low_Rel  \\\n",
      "Date                                                                       \n",
      "2010-01-05       0       0.000323          -0.003236  1.008104  0.993193   \n",
      "2010-01-06       0      -0.006156          -0.002588  1.006477  0.988342   \n",
      "2010-01-07       1      -0.010454          -0.004560  1.002285  0.985635   \n",
      "2010-01-08       0       0.006873          -0.005599  1.019815  0.998679   \n",
      "2010-01-11       0      -0.012801           0.001630  1.001628  0.980788   \n",
      "...            ...            ...                ...       ...       ...   \n",
      "2024-12-23       1      -0.003097           0.000321  1.002084  0.991047   \n",
      "2024-12-24       0       0.009330          -0.001380  1.011389  0.998942   \n",
      "2024-12-26       0      -0.002781          -0.000569  1.004236  0.994420   \n",
      "2024-12-27       0      -0.017453          -0.008044  1.001427  0.981017   \n",
      "2024-12-30       0      -0.013328          -0.010437  1.003497  0.990236   \n",
      "\n",
      "Price       Log_Vol_Change  \n",
      "Date                        \n",
      "2010-01-05        0.258708  \n",
      "2010-01-06        0.156580  \n",
      "2010-01-07       -0.140428  \n",
      "2010-01-08        0.012534  \n",
      "2010-01-11        0.294856  \n",
      "...                    ...  \n",
      "2024-12-23       -1.210562  \n",
      "2024-12-24       -0.983295  \n",
      "2024-12-26        0.134288  \n",
      "2024-12-27        0.793463  \n",
      "2024-12-30       -0.319806  \n",
      "\n",
      "[3772 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine all data\n",
    "if not all_data:\n",
    "    raise RuntimeError(\"No data was downloaded for any tickers. Aborting.\")\n",
    "\n",
    "\n",
    "raw_data = all_data\n",
    "print('raw_data ---------------------------------------------')\n",
    "print(raw_data[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Dataset 1 - Basic OHLCV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 (Basic) created\n",
      "Price       Log_Ret_Close  Log_Ret_Overnight  High_Rel   Low_Rel  \\\n",
      "Date                                                               \n",
      "2010-01-05       0.001727       2.752930e-03  1.004613  0.993709   \n",
      "2010-01-06      -0.016034       1.058689e-07  1.003965  0.983067   \n",
      "2010-01-07      -0.001850       3.690556e-03  1.001181  0.987249   \n",
      "2010-01-08       0.006626      -1.330695e-03  1.008084  0.994104   \n",
      "2010-01-11      -0.008860       3.860972e-03  1.000940  0.979558   \n",
      "2010-01-12      -0.011440      -4.388310e-03  1.002773  0.986759   \n",
      "2010-01-13       0.014007       7.221870e-04  1.014721  0.981864   \n",
      "2010-01-14      -0.005809      -2.566949e-03  1.001666  0.994812   \n",
      "2010-01-15      -0.016853       7.136682e-03  1.003176  0.976011   \n",
      "2010-01-19       0.043288       1.158698e-02  1.032929  0.994768   \n",
      "\n",
      "Price       Log_Vol_Change  Target  \n",
      "Date                                \n",
      "2010-01-05        0.198111       0  \n",
      "2010-01-06       -0.086261       0  \n",
      "2010-01-07       -0.146046       1  \n",
      "2010-01-08       -0.063867       0  \n",
      "2010-01-11        0.032138       0  \n",
      "2010-01-12        0.251591       1  \n",
      "2010-01-13        0.019049       0  \n",
      "2010-01-14       -0.336209       0  \n",
      "2010-01-15        0.316500       1  \n",
      "2010-01-19        0.206062       0  \n"
     ]
    }
   ],
   "source": [
    "# Dataset 1: Basic OHLCV + Target\n",
    "features_to_keep = [\n",
    "    'Log_Ret_Close',\n",
    "    'Log_Ret_Overnight',\n",
    "    'High_Rel',\n",
    "    'Low_Rel',\n",
    "    'Log_Vol_Change',\n",
    "    'Target'  # Don't forget the target!\n",
    "]\n",
    "\n",
    "dataset1 = [data[features_to_keep].copy(deep=True) for data in raw_data]\n",
    "print(f\"Dataset 1 (Basic) created\")\n",
    "print(dataset1[0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Calculate Technical Indicators for Dataset 2\n",
    "\n",
    "Technical indicators to calculate:\n",
    "- **Simple Moving Averages (SMA)**: 10-day, 50-day, 200-day\n",
    "- **Relative Strength Index (RSI)**: 14-day period\n",
    "- **MACD**: 12, 26, 9 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical indicator functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_sma(data, window):\n",
    "    \"\"\"Calculate Simple Moving Average\"\"\"\n",
    "    return data.rolling(window=window).mean()\n",
    "\n",
    "def calculate_rsi(data, window=14):\n",
    "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_macd(data, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calculate MACD and Signal line\"\"\"\n",
    "    ema_fast = data.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = data.ewm(span=slow, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
    "    return macd, signal_line\n",
    "\n",
    "print(\"Technical indicator functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating technical indicators for each ticker...\n",
      "\n",
      "Price       Log_Ret_Close  Log_Ret_Overnight  High_Rel   Low_Rel  \\\n",
      "Date                                                               \n",
      "2010-10-19      -0.027126          -0.046999  1.034179  0.988860   \n",
      "2010-10-20       0.003355          -0.001585  1.016990  0.993107   \n",
      "2010-10-21      -0.003258           0.005876  1.007619  0.982200   \n",
      "2010-10-22      -0.006645          -0.001454  1.003138  0.991038   \n",
      "2010-10-25       0.004446           0.005255  1.008120  0.997897   \n",
      "\n",
      "Price       Log_Vol_Change    SMA-10    SMA-50   SMA-200        RSI      MACD  \\\n",
      "Date                                                                            \n",
      "2010-10-19        0.120339  9.030483  8.140073  7.376566  69.540600  0.321368   \n",
      "2010-10-20       -0.535526  9.094484  8.170736  7.390984  74.786955  0.320406   \n",
      "2010-10-21       -0.268935  9.155365  8.206323  7.405762  75.092795  0.313584   \n",
      "2010-10-22       -0.391586  9.195554  8.239721  7.420291  77.737354  0.299762   \n",
      "2010-10-25        0.051457  9.235982  8.275555  7.434816  73.118189  0.288794   \n",
      "\n",
      "Price       Target  \n",
      "Date                \n",
      "2010-10-19       1  \n",
      "2010-10-20       0  \n",
      "2010-10-21       0  \n",
      "2010-10-22       1  \n",
      "2010-10-25       0  \n",
      "Price       Log_Ret_Close  Log_Ret_Overnight  High_Rel   Low_Rel  \\\n",
      "Date                                                               \n",
      "2010-10-19      -0.028282          -0.021532  1.003957  0.987337   \n",
      "2010-10-20       0.008332           0.006355  1.005542  0.993666   \n",
      "2010-10-21       0.004337           0.003550  1.005512  0.986220   \n",
      "2010-10-22      -0.001575           0.003926  1.000784  0.990204   \n",
      "2010-10-25      -0.007514          -0.005531  1.004358  0.997227   \n",
      "\n",
      "Price       Log_Vol_Change     SMA-10     SMA-50    SMA-200        RSI  \\\n",
      "Date                                                                     \n",
      "2010-10-19        0.313876  18.990014  18.645974  20.459543  58.720943   \n",
      "2010-10-20       -0.161535  19.056864  18.651641  20.439774  61.263751   \n",
      "2010-10-21       -0.117732  19.124474  18.662154  20.421135  64.285857   \n",
      "2010-10-22       -0.660828  19.186006  18.677650  20.403541  72.896954   \n",
      "2010-10-25        0.678264  19.231587  18.691620  20.384439  64.189306   \n",
      "\n",
      "Price           MACD  Target  \n",
      "Date                          \n",
      "2010-10-19  0.154604       1  \n",
      "2010-10-20  0.159490       1  \n",
      "2010-10-21  0.168167       0  \n",
      "2010-10-22  0.170624       0  \n",
      "2010-10-25  0.159091       1  \n"
     ]
    }
   ],
   "source": [
    "# Create Dataset 2 with technical indicators\n",
    "dataset2 = [data.copy(deep=True) for data in raw_data]\n",
    "\n",
    "print(\"Calculating technical indicators for each ticker...\\n\")\n",
    "features_to_keep = [\n",
    "    'Log_Ret_Close',\n",
    "    'Log_Ret_Overnight',\n",
    "    'High_Rel',\n",
    "    'Low_Rel',\n",
    "    'Log_Vol_Change',\n",
    "    'SMA-10',\n",
    "    'SMA-50',\n",
    "    'SMA-200',\n",
    "    'RSI',\n",
    "    'MACD',\n",
    "    'Target'  # Don't forget the target!\n",
    "    \n",
    "]\n",
    "for i in range(len(dataset2)):\n",
    "    ticker_data = dataset2[i]\n",
    "    ticker_data['SMA-10'] = calculate_sma(ticker_data['Close'], 10)\n",
    "    ticker_data['SMA-50'] = calculate_sma(ticker_data['Close'], 50)\n",
    "    ticker_data['SMA-200'] = calculate_sma(ticker_data['Close'], 200)\n",
    "    \n",
    "    ticker_data['RSI'] = calculate_rsi(ticker_data['Close'])\n",
    "    \n",
    "    ticker_data['MACD'], ticker_data['Signal_Line'] = calculate_macd(ticker_data['Close'])\n",
    "    \n",
    "    dataset2[i] = ticker_data[features_to_keep].copy().dropna()\n",
    "    \n",
    "    print(dataset2[i].head(5))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Clean Data - Drop Rows with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Split Data into Train and Test Sets\n",
    "\n",
    "- **Training**: 2010-2021\n",
    "- **Testing**: 2022-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price       Log_Ret_Close  Log_Ret_Overnight  High_Rel   Low_Rel  \\\n",
      "Date                                                               \n",
      "2010-01-05       0.001727       2.752930e-03  1.004613  0.993709   \n",
      "2010-01-06      -0.016034       1.058689e-07  1.003965  0.983067   \n",
      "2010-01-07      -0.001850       3.690556e-03  1.001181  0.987249   \n",
      "2010-01-08       0.006626      -1.330695e-03  1.008084  0.994104   \n",
      "2010-01-11      -0.008860       3.860972e-03  1.000940  0.979558   \n",
      "\n",
      "Price       Log_Vol_Change  Target  \n",
      "Date                                \n",
      "2010-01-05        0.198111       0  \n",
      "2010-01-06       -0.086261       0  \n",
      "2010-01-07       -0.146046       1  \n",
      "2010-01-08       -0.063867       0  \n",
      "2010-01-11        0.032138       0  \n",
      "Price       Log_Ret_Close  Log_Ret_Overnight  High_Rel   Low_Rel  \\\n",
      "Date                                                               \n",
      "2010-10-19      -0.027126          -0.046999  1.034179  0.988860   \n",
      "2010-10-20       0.003355          -0.001585  1.016990  0.993107   \n",
      "2010-10-21      -0.003258           0.005876  1.007619  0.982200   \n",
      "2010-10-22      -0.006645          -0.001454  1.003138  0.991038   \n",
      "2010-10-25       0.004446           0.005255  1.008120  0.997897   \n",
      "\n",
      "Price       Log_Vol_Change    SMA-10    SMA-50   SMA-200        RSI      MACD  \\\n",
      "Date                                                                            \n",
      "2010-10-19        0.120339  9.030483  8.140073  7.376566  69.540600  0.321368   \n",
      "2010-10-20       -0.535526  9.094484  8.170736  7.390984  74.786955  0.320406   \n",
      "2010-10-21       -0.268935  9.155365  8.206323  7.405762  75.092795  0.313584   \n",
      "2010-10-22       -0.391586  9.195554  8.239721  7.420291  77.737354  0.299762   \n",
      "2010-10-25        0.051457  9.235982  8.275555  7.434816  73.118189  0.288794   \n",
      "\n",
      "Price       Target  \n",
      "Date                \n",
      "2010-10-19       1  \n",
      "2010-10-20       0  \n",
      "2010-10-21       0  \n",
      "2010-10-22       1  \n",
      "2010-10-25       0  \n",
      "============================================================\n",
      "Dataset 1 (Basic OHLCV)\n",
      "============================================================\n",
      "Training set: 6,040 rows (2010-01-05 00:00:00 to 2021-12-31 00:00:00)\n",
      "Testing set:  1,504 rows (2022-01-03 00:00:00 to 2024-12-30 00:00:00)\n",
      "\n",
      "Target distribution - Train: 52.81% positive\n",
      "Target distribution - Test:  52.39% positive\n",
      "\n",
      "============================================================\n",
      "Dataset 2 (With Technical Indicators)\n",
      "============================================================\n",
      "Training set: 5,642 rows (2010-10-19 00:00:00 to 2021-12-31 00:00:00)\n",
      "Testing set:  1,504 rows (2022-01-03 00:00:00 to 2024-12-30 00:00:00)\n",
      "\n",
      "Target distribution - Train: 52.73% positive\n",
      "Target distribution - Test:  52.39% positive\n"
     ]
    }
   ],
   "source": [
    "# Define split date\n",
    "split_date = '2022-01-01'\n",
    "\n",
    "# Combine the DFs\n",
    "\n",
    "dataset1_full = pd.concat(dataset1)\n",
    "\n",
    "\n",
    "dataset2_full = pd.concat(dataset2)\n",
    "\n",
    "print(dataset1_full.head(5))\n",
    "print(dataset2_full.head(5))\n",
    "\n",
    "# Split Dataset 1\n",
    "\n",
    "dataset1_train = dataset1_full[dataset1_full.index < split_date].copy()\n",
    "dataset1_test = dataset1_full[dataset1_full.index >= split_date].copy()\n",
    "\n",
    "# Split Dataset 2\n",
    "dataset2_train = dataset2_full[dataset2_full.index < split_date].copy()\n",
    "dataset2_test = dataset2_full[dataset2_full.index >= split_date].copy()\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Dataset 1 (Basic OHLCV)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training set: {dataset1_train.shape[0]:,} rows ({dataset1_train.index.min()} to {dataset1_train.index.max()})\")\n",
    "print(f\"Testing set:  {dataset1_test.shape[0]:,} rows ({dataset1_test.index.min()} to {dataset1_test.index.max()})\")\n",
    "print(f\"\\nTarget distribution - Train: {dataset1_train['Target'].mean()*100:.2f}% positive\")\n",
    "print(f\"Target distribution - Test:  {dataset1_test['Target'].mean()*100:.2f}% positive\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Dataset 2 (With Technical Indicators)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training set: {dataset2_train.shape[0]:,} rows ({dataset2_train.index.min()} to {dataset2_train.index.max()})\")\n",
    "print(f\"Testing set:  {dataset2_test.shape[0]:,} rows ({dataset2_test.index.min()} to {dataset2_test.index.max()})\")\n",
    "print(f\"\\nTarget distribution - Train: {dataset2_train['Target'].mean()*100:.2f}% positive\")\n",
    "print(f\"Target distribution - Test:  {dataset2_test['Target'].mean()*100:.2f}% positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Datasets to CSV and Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Dataset 1 (Basic OHLCV)...\n",
      "âœ“ Dataset 1 saved\n",
      "\n",
      "Saving Dataset 2 (With Technical Indicators)...\n",
      "âœ“ Dataset 2 saved\n",
      "\n",
      "============================================================\n",
      "All datasets saved successfully!\n",
      "============================================================\n",
      "\n",
      "Files created in ../data/stationary/ directory:\n",
      "  - dataset1_train.csv / .parquet\n",
      "  - dataset1_test.csv / .parquet\n",
      "  - dataset2_train.csv / .parquet\n",
      "  - dataset2_test.csv / .parquet\n"
     ]
    }
   ],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "# Save Dataset 1 (Basic)\n",
    "print(\"Saving Dataset 1 (Basic OHLCV)...\")\n",
    "dataset1_train.to_csv('../data/stationary/dataset1_train.csv', index=False)\n",
    "dataset1_test.to_csv('../data/stationary/dataset1_test.csv', index=False)\n",
    "dataset1_train.to_parquet('../data/stationary/dataset1_train.parquet', index=False)\n",
    "dataset1_test.to_parquet('../data/stationary/dataset1_test.parquet', index=False)\n",
    "print(\"âœ“ Dataset 1 saved\")\n",
    "\n",
    "# Save Dataset 2 (Enhanced)\n",
    "print(\"\\nSaving Dataset 2 (With Technical Indicators)...\")\n",
    "dataset2_train.to_csv('../data/stationary/dataset2_train.csv', index=False)\n",
    "dataset2_test.to_csv('../data/stationary/dataset2_test.csv', index=False)\n",
    "dataset2_train.to_parquet('../data/stationary/dataset2_train.parquet', index=False)\n",
    "dataset2_test.to_parquet('../data/stationary/dataset2_test.parquet', index=False)\n",
    "print(\"âœ“ Dataset 2 saved\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All datasets saved successfully!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nFiles created in ../data/stationary/ directory:\")\n",
    "print(\"  - dataset1_train.csv / .parquet\")\n",
    "print(\"  - dataset1_test.csv / .parquet\")\n",
    "print(\"  - dataset2_train.csv / .parquet\")\n",
    "print(\"  - dataset2_test.csv / .parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET GENERATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "1. DATA COLLECTION\n",
      "   - Number of stocks: 2\n",
      "   - Date range: 2010-01-01 to 2024-12-31\n",
      "   - Tickers: AAPL, MSFT...\n",
      "\n",
      "2. DATASET 1 (Basic OHLCV)\n",
      "   Columns: ['Log_Ret_Close', 'Log_Ret_Overnight', 'High_Rel', 'Low_Rel', 'Log_Vol_Change', 'Target']\n",
      "   - Training: 6,040 rows, 6 features\n",
      "   - Testing:  1,504 rows, 6 features\n",
      "\n",
      "3. DATASET 2 (With Technical Indicators)\n",
      "   Columns: ['Log_Ret_Close', 'Log_Ret_Overnight', 'High_Rel', 'Low_Rel', 'Log_Vol_Change', 'SMA-10', 'SMA-50', 'SMA-200', 'RSI', 'MACD', 'Target']\n",
      "   - Training: 5,642 rows, 11 features\n",
      "   - Testing:  1,504 rows, 11 features\n",
      "\n",
      "4. TECHNICAL INDICATORS INCLUDED\n",
      "   - SMA_10, SMA_50, SMA_200 (Simple Moving Averages)\n",
      "   - RSI_14 (Relative Strength Index)\n",
      "   - MACD, MACD_Signal, MACD_Histogram\n",
      "\n",
      "5. FILE OUTPUTS\n",
      "   CSV and Parquet formats saved to ../data/ directory\n",
      "\n",
      "================================================================================\n",
      "Dataset generation complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATASET GENERATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DATA COLLECTION\")\n",
    "print(f\"   - Number of stocks: {len(top_50_tickers)}\")\n",
    "print(f\"   - Date range: 2010-01-01 to 2024-12-31\")\n",
    "print(f\"   - Tickers: {', '.join(top_50_tickers[:10])}...\")\n",
    "\n",
    "print(\"\\n2. DATASET 1 (Basic OHLCV)\")\n",
    "print(f\"   Columns: {list(dataset1_train.columns)}\")\n",
    "print(f\"   - Training: {dataset1_train.shape[0]:,} rows, {dataset1_train.shape[1]} features\")\n",
    "print(f\"   - Testing:  {dataset1_test.shape[0]:,} rows, {dataset1_test.shape[1]} features\")\n",
    "\n",
    "print(\"\\n3. DATASET 2 (With Technical Indicators)\")\n",
    "print(f\"   Columns: {list(dataset2_train.columns)}\")\n",
    "print(f\"   - Training: {dataset2_train.shape[0]:,} rows, {dataset2_train.shape[1]} features\")\n",
    "print(f\"   - Testing:  {dataset2_test.shape[0]:,} rows, {dataset2_test.shape[1]} features\")\n",
    "\n",
    "print(\"\\n4. TECHNICAL INDICATORS INCLUDED\")\n",
    "print(\"   - SMA_10, SMA_50, SMA_200 (Simple Moving Averages)\")\n",
    "print(\"   - RSI_14 (Relative Strength Index)\")\n",
    "print(\"   - MACD, MACD_Signal, MACD_Histogram\")\n",
    "\n",
    "print(\"\\n5. FILE OUTPUTS\")\n",
    "print(\"   CSV and Parquet formats saved to ../data/ directory\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Dataset generation complete!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
